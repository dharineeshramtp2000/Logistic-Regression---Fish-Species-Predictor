{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPmvh3fz+QNK+wtegDKC5gQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dharineeshramtp2000/Logistic-Regression-Fish-Species-Predictor/blob/master/Fish%20species%20Predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmeaUi3cXjJ6",
        "colab_type": "text"
      },
      "source": [
        "Import the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0gG7dpoXchH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwp1EEG2XqUH",
        "colab_type": "text"
      },
      "source": [
        "Importing the Dataset. Here we use the dataset from [Kaggle](https://www.kaggle.com/aungpyaeap/fish-market).\n",
        "![](https://thumbor.forbes.com/thumbor/960x0/https%3A%2F%2Fblogs-images.forbes.com%2Fgrrlscientist%2Ffiles%2F2018%2F09%2Foo_231160-1200x865.jpg)\n",
        "---\n",
        "Here the fishes are separated on the basis of their height, length, width, weight(a.k.a independent variables)\n",
        "\n",
        "So our dependent variable consists of the names of the fish species.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tifsPeCMYo2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Dataset = pd.read_csv(\"Fish.csv\")\n",
        "X = Dataset.iloc[ : ,[1,2,3,5,6]].values\n",
        "y = Dataset.iloc[ : , 0].values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbg5jOhBYx2V",
        "colab_type": "text"
      },
      "source": [
        "Now lets feature scale our independent variables from our famous [scikit](https://scikit-learn.org/stable/) library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Widc4BbzZNvL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X = sc_X.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2CaoxRcZeMd",
        "colab_type": "text"
      },
      "source": [
        "Splitting the dataset into training and testing and performing a good shuffle of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VP83grDqZlOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train , X_test , y_train, y_test = train_test_split(X , y , test_size = 0.3, random_state= 42,shuffle= True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E82SIY2PZmNj",
        "colab_type": "text"
      },
      "source": [
        "Now lets define our Logistic Regression model.\n",
        "Here we define Liblinear algorithm based LR with one vs all stratergy.\n",
        "We can also use other methods like Gradient Descent, LBFGS etc..,\n",
        "But we stick to Liblinear as it performs well for small data.\n",
        "\n",
        "Feel free to use the [Documnetaton for Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9bLh52NbAxk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "6004e41c-dd2c-4bc7-9bd7-2bade5cabc5b"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(max_iter=1000, random_state = 0, multi_class='ovr', solver='lbfgs')\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
              "                   multi_class='ovr', n_jobs=None, penalty='l2', random_state=0,\n",
              "                   solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2j8E0L4b78d",
        "colab_type": "text"
      },
      "source": [
        "Now lets predict with our test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fMBI0Utb_rW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = classifier.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1xGFcQIcDJv",
        "colab_type": "text"
      },
      "source": [
        "Its time for evaluating our model.\n",
        "![](https://hatrabbits.com/wp-content/uploads/2018/08/brainstorm-criteria-evaluation.jpg)\n",
        "\n",
        "---\n",
        "Lets first predict how our model is fitting for our training set\n",
        "We use the famous\n",
        "1.   f1 score\n",
        "2.   accuracy \n",
        "to evaluate the model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEjsrO7ycCIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AodntoNGc62e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "be7c4152-ebfd-4fa0-bd04-1943e66524c5"
      },
      "source": [
        "acc_train = accuracy_score(y_train, classifier.predict(X_train))\n",
        "f1_train = f1_score(y_train, classifier.predict(X_train), average= 'weighted')\n",
        "\n",
        "print(\"Traing set results\")\n",
        "print(\"ACCURACY ---------------------->\",acc_train)\n",
        "print(\"F1 SCORE ---------------------->\",f1_train)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traing set results\n",
            "ACCURACY ----------------------> 0.7747747747747747\n",
            "F1 SCORE ----------------------> 0.7052162396342622\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGihP6W9d3-E",
        "colab_type": "text"
      },
      "source": [
        "Now lets see how well is our model. So now lets evaluate with our test set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAjgDCMbeCql",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "a577a72a-6472-4bea-945a-dc33573becbd"
      },
      "source": [
        "acc_test = accuracy_score(y_test, y_pred)\n",
        "f1_test = f1_score(y_test, y_pred, average= 'weighted')\n",
        "\n",
        "print(\"Test set results\")\n",
        "print(\"ACCURACY ---------------------->\",acc_test)\n",
        "print(\"F1 SCORE ---------------------->\",f1_test)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set results\n",
            "ACCURACY ----------------------> 0.8333333333333334\n",
            "F1 SCORE ----------------------> 0.7833333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ey2cFvHYehTh",
        "colab_type": "text"
      },
      "source": [
        "Now lets have our famous Confusion Matrix to visually understand."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3MWd1w8etjW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "954c9565-e810-4ab0-b788-36d36aa5b984"
      },
      "source": [
        "cm = confusion_matrix(y_test,y_pred)\n",
        "print(cm)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[13  0  0  0  0  0  0]\n",
            " [ 0  2  0  0  1  0  0]\n",
            " [ 0  0 14  0  0  0  0]\n",
            " [ 0  0  0  5  0  0  0]\n",
            " [ 0  0  4  0  0  0  0]\n",
            " [ 0  0  0  0  0  6  0]\n",
            " [ 0  0  3  0  0  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQxBHanoex-e",
        "colab_type": "text"
      },
      "source": [
        "Our model has worked well with our test set too.\n",
        "The**accuaracy** and **f1 score** for both test and training set is good.\n",
        "Its always to put a question and ask to ourselves that is this the best model?\n",
        "\n",
        "---\n",
        "\n",
        "Obvisouly not!\n",
        "We can still achive our accuracy by changing our models, changing the independent variables, change the metrics and so on.\n",
        "Its great that we have successfully implemented logistic regression with our fish species dataset."
      ]
    }
  ]
}